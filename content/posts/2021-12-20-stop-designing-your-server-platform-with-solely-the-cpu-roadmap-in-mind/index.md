---
title: "Stop designing your server platform with solely the CPU roadmap in mind"
date: 2021-12-20
categories: 
  - "ai"
tags: 
  - "ai"
  - "ml"
  - "nvidia"
coverImage: "DPU-NVIDIA.jpeg"
---

Over the last 20 years, we designed our core data center platform following the CPU roadmap. But in today's world, the devices attached to the processor make radical and revolutionary improvements, catering to the needs of the new workloads. I'm talking about devices like the GPU, the network adapter, and its natural offspring, the data processing unit (DPU). In the article "[Project Monterey and the need for network cycles offload for ML workloads](https://frankdenneman.nl/2021/10/06/project-monterey-and-the-need-for-network-cycles-offload-for-ml-workloads/)" I zoom into what's in store for us data center architects in the upcoming years.

[![](images/ML-Infrastructure.svg)](https://frankdenneman.nl/wp-content/uploads/2021/08/ML-Infrastructure.svg)

To service the request of these new workloads, we need to move away from designing a platform solely based on a CPU roadmap and plug these devices in a server as an afterthought. When designing a platform for these new workloads, we have to start holistically designing data center systems.

Together with [Luke Wignall](https://www.linkedin.com/in/ACoAAADbmpEBWMA_GZLjR4fg4QXKXh5yFpr5M4E) from [NVIDIA](https://www.linkedin.com/company/nvidia/), we ([Duncan Epping](https://www.linkedin.com/in/ACoAAACA_IkBycJ1cIlozu_JiVIhq-l0LcSa5sk), [Johan van Amersfoort](https://www.linkedin.com/in/ACoAAAJp6roBXCjrEMITDiX537tQpDdxAZtY9YA), and I) discuss DPU technology and other efforts to run and manage modern workloads in episode 5 of the Unexplored Territory podcast.

Apple: [apple.co/3lYZGCF](https://t.co/UbfpcmTx8s)

Google: [bit.ly/3oQVarH](https://t.co/XlhvVtB61S)

Spotify: [spoti.fi/3INgN3R](https://t.co/rLGZjpWOWv)

Or anywhere else where you get your podcasts!
